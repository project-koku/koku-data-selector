import datetime
import calendar
import logging
import os
import uuid
import requests
import pandas as pd
from datetime import timedelta
from azure.identity import DefaultAzureCredential
from azure.storage.blob import BlobServiceClient, ContainerClient

import azure.functions as func


def main(mytimer: func.TimerRequest) -> None:
    utc_timestamp = datetime.datetime.utcnow().replace(
        tzinfo=datetime.timezone.utc).isoformat()

    default_credential = DefaultAzureCredential()

    now = datetime.datetime.now()
    _, num_days = calendar.monthrange(now.year, now.month)
    month_end = now.replace(day=num_days)
    month_start = now.replace(day=1)
    year = now.strftime("%Y")
    month = now.strftime("%m")
    day = now.strftime("%d")

    # Finalized data
    # Appends finalized data to the last day of the previous month

    # month_end = now.replace(day=1) - timedelta(days=1)
    # month_start = last_month_end.replace(day=1)
    # month = last_month.strftime("%m")
    # day = last_month.strftime("%d")

    output_blob_name=f"{year}/{month}/{day}/{uuid.uuid4()}.csv"

    # Required vars to update
    USER = os.getenv('UsernameFromVault')                                   # Cost management username
    PASS = os.getenv('PasswordFromVault')                                   # Cost management password
    source_id = "CHANGE-ME"                                                 # Cost management source_id
    cost_export_store = "https://CHANGE-ME.blob.core.windows.net"           # Cost export storage account url
    cost_export_container = "CHANGE-ME"                                     # Cost export container
    cost_export_dir = "eport-dir/export-name"                               # Cost export dir + Cost export name
    filtered_data_store = "https://CHANGE-ME.blob.core.windows.net"         # Filtered data storage account url
    filtered_data_container = "CHANGE-ME"                                   # Filtered data container
    timeformat = "%Y%m%d"
    report_range = f"{month_start.strftime(timeformat)}-{month_end.strftime(timeformat)}"
    report_path = f"{cost_export_dir}/{report_range}"

    # Create the BlobServiceClient object
    blob_service_client = BlobServiceClient(filtered_data_store, credential=default_credential)
    container_client = ContainerClient(cost_export_store, credential=default_credential, container_name=cost_export_container)

    blob_list = container_client.list_blobs(name_starts_with=report_path)
    latest_blob = None
    for blob in blob_list:
        if latest_blob:
            if blob.last_modified > latest_blob.last_modified:
                latest_blob = blob
        else:
            latest_blob = blob

    bc = container_client.get_blob_client(blob=latest_blob)
    data = bc.download_blob()
    blobjct = "/tmp/blob.csv"
    with open(blobjct, "wb") as f:
        data.readinto(f)
    df = pd.read_csv(blobjct)

    filtered_data = df.loc[((df["publisherType"] == "Marketplace") & ((df["publisherName"].astype(str).str.contains("Red Hat")) | (((df["publisherName"] == "Microsoft") | (df["publisherName"] == "Azure")) & (df['meterSubCategory'].astype(str).str.contains("Red Hat") | df['serviceInfo2'].astype(str).str.contains("Red Hat")))))]

    filtered_data_csv = filtered_data.to_csv (index_label="idx", encoding = "utf-8")

    blob_client = blob_service_client.get_blob_client(container=filtered_data_container, blob=output_blob_name)

    blob_client.upload_blob(filtered_data_csv, overwrite=True)

    # Post results to console.redhat.com API
    url = "https://console.redhat.com/api/cost-management/v1/ingress/reports/"
    json_data = {"source": source_id, "reports_list": [f"{filtered_data_container}/{output_blob_name}"], "bill_year": year, "bill_month": month}
    resp = requests.post(url, json=json_data, auth=(USER, PASS))
    logging.info(f'Post result: {resp}')

    if mytimer.past_due:
        logging.info('The timer is past due!')

    logging.info('Python timer trigger function ran at %s', utc_timestamp)
