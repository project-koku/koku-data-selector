import datetime
import logging
import uuid
import requests
import pandas as pd
from azure.identity import DefaultAzureCredential
from azure.storage.blob import BlobServiceClient, ContainerClient

import azure.functions as func


def main(mytimer: func.TimerRequest) -> None:
    utc_timestamp = datetime.datetime.utcnow().replace(
        tzinfo=datetime.timezone.utc).isoformat()

    default_credential = DefaultAzureCredential()

    now = datetime.datetime.now()
    year = now.strftime("%Y")
    month = now.strftime("%m")
    day = now.strftime("%d")
    output_blob_name=f"{year}/{month}/{day}/{uuid.uuid4()}.csv"

    # Required vars to update
    source_uuid = "CHANGE-ME"                                               # Cost management source_uuid
    USER = "CHANGE-ME"                                                      # Cost management username
    PASS = "CHANGE-ME"                                                      # Cost management password
    cost_export_store = "https://CHANGE-ME.blob.core.windows.net"           # Cost export storage account url
    cost_export_container = "CHANGE-ME"                                     # Cost export container
    filtered_data_store = "https://CHANGE-ME.blob.core.windows.net"         # Filtered data storage account url
    filtered_data_container = "CHANGE-ME"                                   # Filtered data container

    # Create the BlobServiceClient object
    blob_service_client = BlobServiceClient(filtered_data_account_url, credential=default_credential)
    container_client = ContainerClient(cost_export_store, credential=default_credential, container_name=cost_export_container)

    blob_list = container_client.list_blobs()
    latest_blob = None
    for blob in blob_list:
        if latest_blob:
            if blob.last_modified > latest_blob.last_modified:
                latest_blob = blob
        else:
            latest_blob = blob

    bc = container_client.get_blob_client(blob=latest_blob)
    data = bc.download_blob()
    blobjct = "/tmp/blob.csv"
    with open(blobjct, "wb") as f:
        data.readinto(f)
    df = pd.read_csv(blobjct)

    filtered_data = df.loc[((df["publisherType"] == "Marketplace") & (df["publisherName"].astype(str).str.contains("Red Hat"))) | ((df["publisherName"] == "Microsoft") & (df['meterSubCategory'].astype(str).str.contains("Red Hat") | df['serviceInfo2'].astype(str).str.contains("Red Hat")))]

    filtered_data_csv = filtered_data.to_csv (index_label="idx", encoding = "utf-8")

    blob_client = blob_service_client.get_blob_client(container=filtered_data_container, blob=output_blob_name)

    blob_client.upload_blob(filtered_data_csv, overwrite=True)
    
    # Post results to console.redhat.com API
    url = "https://console.redhat.com/api/cost-management/v1/ingress/reports/"
    json_data = {"source": source_uuid, "reports_list": [f"{filtered_data_container}/{output_blob_name}"], "bill_year": year, "bill_month": month}
    resp = requests.post(url, json=json_data, auth=(USER, PASS))
    logging.info(f'Post result: {resp}')

    if mytimer.past_due:
        logging.info('The timer is past due!')

    logging.info('Python timer trigger function ran at %s', utc_timestamp)